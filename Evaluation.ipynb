{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyN/uWxPQVnD+2hNILaa7/Un"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import files\n","import json\n","import os\n","import re\n","import numpy as np\n","import calendar"],"metadata":{"id":"I_e5Kj6EgrKm","executionInfo":{"status":"ok","timestamp":1748555767751,"user_tz":-120,"elapsed":49,"user":{"displayName":"Hanna Kulik","userId":"10245236037284873747"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["uploaded = files.upload()"],"metadata":{"id":"5bkt1LxbjM8U","colab":{"base_uri":"https://localhost:8080/","height":177},"executionInfo":{"status":"ok","timestamp":1748555812883,"user_tz":-120,"elapsed":43137,"user":{"displayName":"Hanna Kulik","userId":"10245236037284873747"}},"outputId":"3e0af47c-85f5-49b6-bef4-fa5f17df013c"},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-8463ad8c-c70f-4ef1-ac11-722fda0824f9\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8463ad8c-c70f-4ef1-ac11-722fda0824f9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving predictions_BATCHED_original_offset_iso_date.jsonl to predictions_BATCHED_original_offset_iso_date.jsonl\n","Saving predictions_BATCHED_original_offset_original_date.jsonl to predictions_BATCHED_original_offset_original_date.jsonl\n","Saving predictions_BATCHED_total_months_numeric_offset_ordinal_month_date.jsonl to predictions_BATCHED_total_months_numeric_offset_ordinal_month_date.jsonl\n","Saving predictions_BATCHED_total_months_word_offset_full_words_date.jsonl to predictions_BATCHED_total_months_word_offset_full_words_date.jsonl\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"q6mFTa5wgjew","executionInfo":{"status":"ok","timestamp":1748555819469,"user_tz":-120,"elapsed":49,"user":{"displayName":"Hanna Kulik","userId":"10245236037284873747"}}},"outputs":[],"source":["import numpy as np\n","import calendar\n","\n","answer_column_name = 'llama_prediction'\n","results_output_dir = \"/content/results\"\n","os.makedirs(results_output_dir, exist_ok=True)\n","\n","# Build a lookup from month names / abbreviations → zero‑padded month number\n","_month_lookup = {}\n","for month_idx in range(1, 13):\n","    month_num_str = f\"{month_idx:02d}\"\n","    month_forms = [\n","        calendar.month_name[month_idx].lower(),\n","        calendar.month_abbr[month_idx].lower().rstrip('.')\n","    ]\n","    for form in month_forms:\n","      for prefix_len in range(3, len(form) + 1):\n","            _month_lookup[form[:prefix_len]] = month_num_str\n","\n","_year_re = re.compile(r\"(\\d{4})\")\n","\n","def _normalize_text(txt: str) -> str:\n","    \"\"\"\n","    Canonicalise various date strings to ISO 'YYYY-MM' where possible,\n","    otherwise fallback to lowercased / whitespace-collapsed text.\n","\n","    Examples:\n","        \"Mar, 1789\"   -> \"1789-03\"\n","        \"march 1789\"  -> \"1789-03\"\n","        \"1789-03-12\"  -> \"1789-03\"\n","        \"1789-03\"     -> \"1789-03\"\n","    \"\"\"\n","    if not txt or not isinstance(txt, str):\n","        return \"\"\n","\n","    s = \" \".join(txt.strip().lower().split()).replace(\"*\", \"\")\n","\n","    # 1) ISO patterns: YYYY-MM or YYYY-MM-DD\n","    m_iso = re.match(r\"^(?P<year>\\d{4})-(?P<month>\\d{2})(?:-\\d{2})?$\", s)\n","    if m_iso:\n","        return f\"{m_iso.group('year')}-{m_iso.group('month')}\"\n","\n","    # 2) Month name patterns\n","    month_pattern = \"|\".join(re.escape(month) for month in _month_lookup.keys())\n","\n","    # Pattern: YYYY month_name [YYYY]?\n","    pattern = rf\"^(?P<year1>\\d{{4}})\\s+(?P<month_name>{month_pattern})[\\.,]?\\s*(?P<year2>\\d{{4}})?$\"\n","    m_name = re.match(pattern, s)\n","    if m_name:\n","        month_str = m_name.group(\"month_name\")\n","        year_str = m_name.group(\"year1\")\n","        month_num = _month_lookup.get(month_str)\n","        if month_num:\n","            return f\"{year_str}-{month_num}\"\n","\n","    # Pattern: month_name YYYY\n","    m_month_year = re.match(rf\"^(?P<month_name>{month_pattern})[\\.,]?\\s+(?P<year>\\d{{4}})$\", s)\n","    if m_month_year:\n","        month_num = _month_lookup.get(m_month_year.group(\"month_name\"))\n","        if month_num:\n","            return f\"{m_month_year.group('year')}-{month_num}\"\n","\n","    # 3) If no conversion matched, return the cleaned text\n","    return s\n","\n","# Extract the first year found in the text\n","def _extract_year(txt: str):\n","    m = _year_re.search(txt)\n","    return int(m.group(1)) if m else None\n","\n","\n","def _reference_year(question: str):\n","    \"\"\"\n","    Extract the YYYY that appears *last* in the question –\n","    this is the base date in all L1 questions like '... after Jul, 1699'.\n","    \"\"\"\n","    years = _year_re.findall(question)\n","    return int(years[-1]) if years else None\n","\n","\n","def evaluate_predictions(results_for_this_dataset, answer_column_name, dataset_filename, results_output_dir):\n","\n","    g_em, g_abs_err, g_trend_ok, count_year = 0, 0, 0, 0\n","    total_examples = len(results_for_this_dataset)\n","\n","    for item in results_for_this_dataset:\n","        # Extract gold and predicted answers\n","        gold = (item[\"text_answers\"][\"text\"][0]\n","                if isinstance(item[\"text_answers\"], dict)\n","                else item[\"text_answers\"])\n","        pred = item.get(answer_column_name, \"\")\n","        question = item[\"original_question\"]\n","\n","        # Exact Match\n","        if _normalize_text(gold) in _normalize_text(pred):\n","            g_em += 1\n","        #else:\n","           # print(_normalize_text(pred), _normalize_text(gold))\n","\n","        # Year-based metrics\n","        year_gold = _extract_year(gold)\n","        year_pred = _extract_year(pred)\n","        year_ref = _reference_year(question)\n","\n","        if year_gold is not None and year_pred is not None:\n","            g_abs_err += abs(year_pred - year_gold)\n","\n","            # Trend: sign wrt reference year\n","            if year_ref is not None:\n","                gold_sign = np.sign(year_gold - year_ref)\n","                pred_sign = np.sign(year_pred - year_ref)\n","                if gold_sign == pred_sign and gold_sign != 0:\n","                    g_trend_ok += 1\n","            count_year += 1\n","\n","    exact_match = g_em / total_examples if total_examples else 0.0\n","    mae = g_abs_err / count_year if count_year else 0.0\n","    trend_accuracy = g_trend_ok / count_year if count_year else 0.0\n","\n","    print(f\"=== Evaluation for {dataset_filename} ===\")\n","    print(f\"  Exact Match        : {exact_match:.4f}\")\n","    print(f\"  Mean Absolute Error: {mae:.4f}\")\n","    print(f\"  Trend Accuracy     : {trend_accuracy:.4f}\")\n","\n","    # Save metrics to JSON file\n","    metrics_path = os.path.join(results_output_dir,\n","                                f\"metrics_{dataset_filename.replace('.jsonl', '.json')}\")\n","    metrics = {\n","        \"dataset\": dataset_filename,\n","        \"num_examples\": total_examples,\n","        \"exact_match\": exact_match,\n","        \"mae_year\": mae,\n","        \"trend_accuracy\": trend_accuracy,\n","    }\n","\n","    with open(metrics_path, 'w', encoding='utf-8') as mf:\n","        json.dump(metrics, mf, indent=2)\n","\n","    return metrics"]},{"cell_type":"code","source":["for filename in uploaded.keys():\n","    print(f\"\\nProcessing {filename}...\")\n","\n","    results_for_this_dataset = []\n","    with open(filename, 'r', encoding='utf-8') as f:\n","        for line in f:\n","            results_for_this_dataset.append(json.loads(line.strip()))\n","\n","    metrics = evaluate_predictions(\n","        results_for_this_dataset,\n","        answer_column_name,\n","        filename,\n","        results_output_dir\n","    )\n","    print(f\"\\nReturned metrics: {metrics}\")"],"metadata":{"id":"3nVSTCGalGE6","executionInfo":{"status":"ok","timestamp":1748555824306,"user_tz":-120,"elapsed":818,"user":{"displayName":"Hanna Kulik","userId":"10245236037284873747"}},"outputId":"c6409c54-76f3-470e-f388-bdf432770f63","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Processing predictions_BATCHED_original_offset_iso_date.jsonl...\n","=== Evaluation for predictions_BATCHED_original_offset_iso_date.jsonl ===\n","  Exact Match        : 0.3355\n","  Mean Absolute Error: 21.1935\n","  Trend Accuracy     : 0.9080\n","\n","Returned metrics: {'dataset': 'predictions_BATCHED_original_offset_iso_date.jsonl', 'num_examples': 4000, 'exact_match': 0.3355, 'mae_year': 21.193531422561136, 'trend_accuracy': 0.9079673941625033}\n","\n","Processing predictions_BATCHED_original_offset_original_date.jsonl...\n","=== Evaluation for predictions_BATCHED_original_offset_original_date.jsonl ===\n","  Exact Match        : 0.3155\n","  Mean Absolute Error: 23.8682\n","  Trend Accuracy     : 0.9089\n","\n","Returned metrics: {'dataset': 'predictions_BATCHED_original_offset_original_date.jsonl', 'num_examples': 4000, 'exact_match': 0.3155, 'mae_year': 23.868249412992434, 'trend_accuracy': 0.9089486042264545}\n","\n","Processing predictions_BATCHED_total_months_numeric_offset_ordinal_month_date.jsonl...\n","=== Evaluation for predictions_BATCHED_total_months_numeric_offset_ordinal_month_date.jsonl ===\n","  Exact Match        : 0.3287\n","  Mean Absolute Error: 23.8502\n","  Trend Accuracy     : 0.9153\n","\n","Returned metrics: {'dataset': 'predictions_BATCHED_total_months_numeric_offset_ordinal_month_date.jsonl', 'num_examples': 4000, 'exact_match': 0.32875, 'mae_year': 23.850209863588667, 'trend_accuracy': 0.9152675760755509}\n","\n","Processing predictions_BATCHED_total_months_word_offset_full_words_date.jsonl...\n","=== Evaluation for predictions_BATCHED_total_months_word_offset_full_words_date.jsonl ===\n","  Exact Match        : 0.3297\n","  Mean Absolute Error: 18.6789\n","  Trend Accuracy     : 0.9094\n","\n","Returned metrics: {'dataset': 'predictions_BATCHED_total_months_word_offset_full_words_date.jsonl', 'num_examples': 4000, 'exact_match': 0.32975, 'mae_year': 18.67887249736565, 'trend_accuracy': 0.9093782929399368}\n"]}]}]}