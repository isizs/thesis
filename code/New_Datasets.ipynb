{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZDXS3c4Syr2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"0,1,2,3,4,5,6,7\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpDfRE5YRyVO"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install inflect\n",
        "! pip install datasets==2.16.0\n",
        "! pip install hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1WLN8q0PZh_"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datetime import datetime, date, timedelta\n",
        "from collections import defaultdict\n",
        "import inflect\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qfj7YB2mQJ9L"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# point directly to the L1 validation file on the HF repo\n",
        "VAL_L1 = \"https://huggingface.co/datasets/tonytan48/TempReason/resolve/main/test_l1.json\"\n",
        "\n",
        "# load only that file as the \"validation\" split\n",
        "ds = load_dataset(\"json\", data_files={\"validation\": VAL_L1}, )\n",
        "\n",
        "# grab the validation split and print the first 5 examples\n",
        "val = ds[\"validation\"]\n",
        "\n",
        "print(val)\n",
        "\n",
        "inflect_obj = inflect.engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Itn1gibGRF2t"
      },
      "outputs": [],
      "source": [
        "pattern = re.compile(r'''\n",
        "    (?P<offset_str>\n",
        "        (?P<num1>\\d+)\\s*(?P<unit1>years?|months?)     # first offset\n",
        "        (?:\\s*and\\s*(?P<num2>\\d+)\\s*(?P<unit2>years?|months?))?  # optional second offset\n",
        "    )\n",
        "    \\s*\n",
        "    (?P<direction>after|before)\\s*\n",
        "    (?P<date_str>\n",
        "        (?P<month>[A-Za-z]+),\\s*(?P<year>\\d{4}) # base date\n",
        "    )\n",
        "''', re.IGNORECASE | re.VERBOSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMCOGASwUMCX"
      },
      "outputs": [],
      "source": [
        "def parse_question(q:str):\n",
        "    m = pattern.search(q)\n",
        "    if not m:\n",
        "      raise ValueError(f\"Could not parse question: {q}\")\n",
        "    parsed_components = m.groupdict()\n",
        "\n",
        "    # initialize\n",
        "    offset = {\"year\": 0, \"month\": 0}\n",
        "\n",
        "    # populate year/month\n",
        "    for i in (1, 2):\n",
        "      num_key = f\"num{i}\"\n",
        "      unit_key = f\"unit{i}\"\n",
        "      num_val = parsed_components.get(num_key)\n",
        "      unit_val = parsed_components.get(unit_key)\n",
        "\n",
        "      if num_val and unit_val:\n",
        "        num = int(num_val)\n",
        "        unit = unit_val.lower().rstrip('s')\n",
        "        if unit in offset:\n",
        "          offset[unit] += num\n",
        "\n",
        "    # build base_date (use day=1 by convention)\n",
        "    mon_num = datetime.strptime(parsed_components[\"month\"][:3], \"%b\").month\n",
        "    yr = int(parsed_components[\"year\"])\n",
        "    base_date = date(yr, mon_num, 1)\n",
        "\n",
        "    # extract direction and the original string parts\n",
        "    direction = parsed_components[\"direction\"].lower()\n",
        "    original_offset_str = parsed_components[\"offset_str\"].strip()\n",
        "    original_date_str = parsed_components[\"date_str\"].strip()\n",
        "\n",
        "\n",
        "    return {\n",
        "        \"offset\": offset,\n",
        "        \"base_date\": base_date,\n",
        "        \"direction\": direction,\n",
        "        \"original_offset_str\": original_offset_str, # keeping original for one format\n",
        "        \"original_date_str\": original_date_str\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlWm4t_MDfeS"
      },
      "outputs": [],
      "source": [
        "def format_offset_original(offset_info):\n",
        "    return offset_info[\"original_offset_str\"]\n",
        "\n",
        "def format_offset_total_months_numeric(offset_info):\n",
        "    total_months = offset_info[\"offset\"][\"year\"] * 12 + offset_info[\"offset\"][\"month\"]\n",
        "    return f\"{total_months} {inflect_obj.plural('month', total_months)}\"\n",
        "\n",
        "def format_offset_total_months_word(offset_info):\n",
        "    total_months = offset_info[\"offset\"][\"year\"] * 12 + offset_info[\"offset\"][\"month\"]\n",
        "    month_word = inflect_obj.number_to_words(total_months)\n",
        "    return f\"{month_word} {inflect_obj.plural('month', total_months)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq3N35VpNenv"
      },
      "outputs": [],
      "source": [
        "def format_base_date_original(offset_info):\n",
        "    return offset_info[\"original_date_str\"]\n",
        "\n",
        "def format_base_date_iso(offset_info):   # YYYY-MM\n",
        "    base_date = offset_info[\"base_date\"]\n",
        "    return f\"{base_date.year}-{base_date.month:02d}\"\n",
        "\n",
        "def format_base_date_ordinal(offset_info):   # 'Nth month of YYYY'\n",
        "    month_num = offset_info[\"base_date\"].month\n",
        "    ordinal_month = inflect_obj.ordinal(month_num)\n",
        "    year = offset_info[\"base_date\"].year\n",
        "    return f\"{ordinal_month} month of {year}\"\n",
        "\n",
        "def format_base_date_words(offset_info):  # 'Nth month of YYYY (words)'\n",
        "    month_num = offset_info[\"base_date\"].month\n",
        "    ordinal_month = inflect_obj.ordinal(month_num) # like 'second'\n",
        "    year = offset_info[\"base_date\"].year\n",
        "    year_words = inflect_obj.number_to_words(year).replace(\",\", \"\") # remove commas like in \"one thousand, nine hundred\"\n",
        "    return f\"{ordinal_month} month of {year_words}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgkQEOU63EgF"
      },
      "outputs": [],
      "source": [
        "ds = load_dataset(\"json\", data_files={\"validation\": VAL_L1}, split=\"validation\")\n",
        "print(f\"Loaded {len(ds)} examples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2I3YVDwdSyr6"
      },
      "outputs": [],
      "source": [
        "ds[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlezFL2bFX48"
      },
      "outputs": [],
      "source": [
        "# define formatters\n",
        "offset_formatters = {\n",
        "    \"original\": format_offset_original,\n",
        "    \"total_months_numeric\": format_offset_total_months_numeric,\n",
        "    \"total_months_word\": format_offset_total_months_word,\n",
        "}\n",
        "\n",
        "base_date_formatters = {\n",
        "    \"original\": format_base_date_original,\n",
        "    \"iso\": format_base_date_iso,\n",
        "    \"ordinal_month\": format_base_date_ordinal,\n",
        "    \"full_words\": format_base_date_words,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "aTEUv-04HQGQ"
      },
      "outputs": [],
      "source": [
        "# keys will be tuples like ('original', 'iso')\n",
        "modified_datasets = defaultdict(list)\n",
        "\n",
        "# process and generate new questions\n",
        "print(\"Generating modified datasets\")\n",
        "processed_count = 0\n",
        "error_count = 0\n",
        "for example in ds:\n",
        "    original_question = example['question']\n",
        "    try:\n",
        "        parsed_info = parse_question(original_question)\n",
        "\n",
        "        # iterate through all combinations of formatters\n",
        "        for offset_name, offset_func in offset_formatters.items():\n",
        "            for date_name, date_func in base_date_formatters.items():\n",
        "                # generate the formatted parts\n",
        "                formatted_offset = offset_func(parsed_info)\n",
        "                formatted_base_date = date_func(parsed_info)\n",
        "                direction = parsed_info[\"direction\"]\n",
        "\n",
        "                # construct the new question\n",
        "                new_question = f\"What is the time {formatted_offset} {direction} {formatted_base_date} in ISO format(YYYY-MM)?\"\n",
        "\n",
        "                # create the new example, preserving other fields\n",
        "                new_example = example.copy()\n",
        "                new_example['question'] = new_question\n",
        "                new_example['original_question'] = original_question\n",
        "                dataset_key = (offset_name, date_name)\n",
        "                modified_datasets[dataset_key].append(new_example)\n",
        "\n",
        "        processed_count += 1\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Skipping due to parsing error: {e}\")\n",
        "        error_count += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping due to unexpected error: {e} for question: {original_question}\")\n",
        "        error_count += 1\n",
        "\n",
        "\n",
        "print(f\"\\nProcessing complete.\")\n",
        "print(f\"Successfully processed: {processed_count}\")\n",
        "print(f\"Errors/Skipped: {error_count}\")\n",
        "print(f\"Generated {len(modified_datasets)} dataset variations.\") # should be 12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rNo4ftxMrk4"
      },
      "outputs": [],
      "source": [
        "print(\"Example Generated Questions\")\n",
        "\n",
        "if ('original', 'iso') in modified_datasets and modified_datasets[('original', 'iso')]:\n",
        "    print(\"\\nFormat: Offset=Original, Base Date=ISO\")\n",
        "    print(f\" Original: {modified_datasets[('original', 'iso')][0]['original_question']}\")\n",
        "    print(f\" Modified: {modified_datasets[('original', 'iso')][0]['question']}\")\n",
        "    print(f\" Answer: {modified_datasets[('original', 'iso')][0]['text_answers']}\")\n",
        "\n",
        "if ('total_months_numeric', 'ordinal_month') in modified_datasets and modified_datasets[('total_months_numeric', 'ordinal_month')]:\n",
        "    print(\"\\nFormat: Offset=Total Months Numeric, Base Date=Ordinal Month\")\n",
        "    print(f\" Original: {modified_datasets[('total_months_numeric', 'ordinal_month')][0]['original_question']}\")\n",
        "    print(f\" Modified: {modified_datasets[('total_months_numeric', 'ordinal_month')][0]['question']}\")\n",
        "    print(f\" Answer: {modified_datasets[('total_months_numeric', 'ordinal_month')][0]['text_answers']}\")\n",
        "\n",
        "if ('total_months_word', 'full_words') in modified_datasets and modified_datasets[('total_months_word', 'full_words')]:\n",
        "    print(\"\\nFormat: Offset=Total Months Word, Base Date=Full Words\")\n",
        "    print(f\" Original: {modified_datasets[('total_months_word', 'full_words')][0]['original_question']}\")\n",
        "    print(f\" Modified: {modified_datasets[('total_months_word', 'full_words')][0]['question']}\")\n",
        "    print(f\" Answer: {modified_datasets[('total_months_word', 'full_words')][0]['text_answers']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7a6cJyq4Y4gS"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lg_IUMfY6vj"
      },
      "outputs": [],
      "source": [
        "output_dir = \"temp_reason_modified_datasets\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "for (offset_fmt, date_fmt), data_list in modified_datasets.items():\n",
        "     filename = f\"{offset_fmt}_offset_{date_fmt}_date.jsonl\"\n",
        "     filepath = os.path.join(output_dir, filename)\n",
        "     print(f\"Saving {filepath}\")\n",
        "     with open(filepath, 'w', encoding='utf-8') as f:\n",
        "         for item in data_list:\n",
        "             json.dump(item, f)\n",
        "             f.write('\\n')\n",
        "print(\"Finished saving.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDI5PqG2-GyC"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, T5ForConditionalGeneration, T5Tokenizer\n",
        "from huggingface_hub import login\n",
        "import re\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNTUfD6evwzC"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bwjC9i_Syr7"
      },
      "outputs": [],
      "source": [
        "print(f\"Number of available GPUs: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "        print(f\"Memory allocated: {torch.cuda.memory_allocated(i) / 1024**3:.2f} GB\")\n",
        "        print(f\"Memory cached: {torch.cuda.memory_reserved(i) / 1024**3:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fWjbaB3Syr7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from huggingface_hub import login\n",
        "login(token=\"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\")\n",
        "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    tokenizer=tokenizer  # This will default to eos_token_id for open-ended generation\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OLcn-cNzUX8"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def generate_batch_response_llama(prompts_batch, max_new_tokens=128):\n",
        "    prompt_messages = [[\n",
        "        {\"role\": \"system\", \"content\": \"You are a Helpful assistant\"},\n",
        "        {\"role\": \"user\", \"content\": \"Answer the following question: \\n\" + prompt + \"\\nExplain how you arrive at the result briefly. Then, on the next line, output **only** the final date in YYYY-MM format, with no extra words\"}] for prompt in prompts_batch]\n",
        "\n",
        "    outputs = pipe(\n",
        "      prompt_messages,\n",
        "      max_new_tokens=max_new_tokens,\n",
        "      )\n",
        "    generated_texts = []\n",
        "\n",
        "    for conv in outputs:\n",
        "        updated_chat = conv[0][\"generated_text\"][-1]['content'].split('\\n')[-1]\n",
        "        generated_texts.append(updated_chat)\n",
        "    return generated_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJkcWDMa25J5"
      },
      "outputs": [],
      "source": [
        "selected_dataset_files = [\n",
        "    \"original_offset_iso_date.jsonl\",\n",
        "    \"total_months_numeric_offset_ordinal_month_date.jsonl\",\n",
        "    \"total_months_word_offset_full_words_date.jsonl\",\n",
        "    \"original_offset_original_date.jsonl\"\n",
        "]\n",
        "results_output_dir = \"./model_predictions_on_4_datasets_BATCHED\"\n",
        "os.makedirs(results_output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB4kobYrNjXh"
      },
      "outputs": [],
      "source": [
        "def create_batches(data_list, batch_size_val):\n",
        "    for i in range(0, len(data_list), batch_size_val):\n",
        "        yield data_list[i:i + batch_size_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huU20GsySyr8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtSowLakQBtG"
      },
      "outputs": [],
      "source": [
        "generated_datasets_dir = \"temp_reason_modified_datasets\"\n",
        "batch_size = 8\n",
        "max_gen_tokens = 128\n",
        "\n",
        "for dataset_filename in selected_dataset_files:\n",
        "    input_filepath = os.path.join(generated_datasets_dir, dataset_filename)\n",
        "    print(f\"\\nProcessing dataset: {dataset_filename}\")\n",
        "\n",
        "    current_dataset_items = []\n",
        "    with open(input_filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            current_dataset_items.append(json.loads(line))\n",
        "    results_for_this_dataset = []\n",
        "\n",
        "    for batch_idx, batch_items in enumerate(create_batches(current_dataset_items, batch_size)):\n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            total_batches = (len(current_dataset_items) + batch_size - 1) // batch_size\n",
        "            print(f\"  Processing Batch {batch_idx + 1}/{total_batches}\")\n",
        "\n",
        "        prompts_batch = [item['original_question'] for item in batch_items]\n",
        "\n",
        "        try:\n",
        "            llama_preds_batch = generate_batch_response_llama(prompts_batch, max_new_tokens=max_gen_tokens)\n",
        "        except Exception as e:\n",
        "            print(f\"    Error Llama on BATCH {batch_idx + 1}: {e}\")\n",
        "            llama_preds_batch = [f\"Error Llama: {e}\"] * len(prompts_batch)\n",
        "\n",
        "\n",
        "        for i, original_item in enumerate(batch_items):\n",
        "                prediction_item = original_item.copy()\n",
        "                prediction_item['llama_prediction'] = llama_preds_batch[i]\n",
        "                results_for_this_dataset.append(prediction_item)\n",
        "\n",
        "\n",
        "    if results_for_this_dataset:\n",
        "        output_filename = f\"predictions_BATCHED_{dataset_filename}\"\n",
        "        output_filepath = os.path.join(results_output_dir, output_filename)\n",
        "\n",
        "        with open(output_filepath, 'w', encoding='utf-8') as f:\n",
        "            for res_item in results_for_this_dataset:\n",
        "                json.dump(res_item, f)\n",
        "                f.write('\\n')\n",
        "\n",
        "print(\"\\nAll selected datasets processed and results saved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D57NzFKSSyr8"
      },
      "outputs": [],
      "source": [
        "answer_column_name = 'llama_prediction'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtidvNfdxL-M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import calendar\n",
        "\n",
        "# Build a lookup from month names / abbreviations → zero‑padded month number\n",
        "_month_lookup = {}\n",
        "for month_idx in range(1, 13):\n",
        "    month_num_str = f\"{month_idx:02d}\"\n",
        "    month_forms = [\n",
        "        calendar.month_name[month_idx].lower(),\n",
        "        calendar.month_abbr[month_idx].lower().rstrip('.')\n",
        "    ]\n",
        "    for form in month_forms:\n",
        "      for prefix_len in range(3, len(form) + 1):\n",
        "            _month_lookup[form[:prefix_len]] = month_num_str\n",
        "\n",
        "_year_re = re.compile(r\"(\\d{4})\")\n",
        "\n",
        "def _normalize_text(txt: str) -> str:\n",
        "    \"\"\"\n",
        "    Canonicalise various date strings to ISO 'YYYY-MM' where possible,\n",
        "    otherwise fallback to lowercased / whitespace-collapsed text.\n",
        "\n",
        "    Examples:\n",
        "        \"Mar, 1789\"   -> \"1789-03\"\n",
        "        \"march 1789\"  -> \"1789-03\"\n",
        "        \"1789-03-12\"  -> \"1789-03\"\n",
        "        \"1789-03\"     -> \"1789-03\"\n",
        "    \"\"\"\n",
        "    if not txt or not isinstance(txt, str):\n",
        "        return \"\"\n",
        "\n",
        "    s = \" \".join(txt.strip().lower().split()).replace(\"*\", \"\")\n",
        "\n",
        "    # 1) ISO patterns: YYYY-MM or YYYY-MM-DD\n",
        "    m_iso = re.match(r\"^(?P<year>\\d{4})-(?P<month>\\d{2})(?:-\\d{2})?$\", s)\n",
        "    if m_iso:\n",
        "        return f\"{m_iso.group('year')}-{m_iso.group('month')}\"\n",
        "\n",
        "    # 2) Month name patterns\n",
        "    month_pattern = \"|\".join(re.escape(month) for month in _month_lookup.keys())\n",
        "\n",
        "    # Pattern: YYYY month_name [YYYY]?\n",
        "    pattern = rf\"^(?P<year1>\\d{{4}})\\s+(?P<month_name>{month_pattern})[\\.,]?\\s*(?P<year2>\\d{{4}})?$\"\n",
        "    m_name = re.match(pattern, s)\n",
        "    if m_name:\n",
        "        month_str = m_name.group(\"month_name\")\n",
        "        year_str = m_name.group(\"year1\")\n",
        "        month_num = _month_lookup.get(month_str)\n",
        "        if month_num:\n",
        "            return f\"{year_str}-{month_num}\"\n",
        "\n",
        "    # Pattern: month_name YYYY\n",
        "    m_month_year = re.match(rf\"^(?P<month_name>{month_pattern})[\\.,]?\\s+(?P<year>\\d{{4}})$\", s)\n",
        "    if m_month_year:\n",
        "        month_num = _month_lookup.get(m_month_year.group(\"month_name\"))\n",
        "        if month_num:\n",
        "            return f\"{m_month_year.group('year')}-{month_num}\"\n",
        "\n",
        "    # 3) If no conversion matched, return the cleaned text\n",
        "    return s\n",
        "\n",
        "# Extract the first year found in the text\n",
        "def _extract_year(txt: str):\n",
        "    m = _year_re.search(txt)\n",
        "    return int(m.group(1)) if m else None\n",
        "\n",
        "\n",
        "def _reference_year(question: str):\n",
        "    \"\"\"\n",
        "    Extract the YYYY that appears *last* in the question –\n",
        "    this is the base date in all L1 questions like '... after Jul, 1699'.\n",
        "    \"\"\"\n",
        "    years = _year_re.findall(question)\n",
        "    return int(years[-1]) if years else None\n",
        "\n",
        "\n",
        "def evaluate_predictions(results_for_this_dataset, answer_column_name, dataset_filename, results_output_dir):\n",
        "\n",
        "    g_em, g_abs_err, g_trend_ok, count_year = 0, 0, 0, 0\n",
        "    total_examples = len(results_for_this_dataset)\n",
        "\n",
        "    for item in results_for_this_dataset:\n",
        "        # Extract gold and predicted answers\n",
        "        gold = (item[\"text_answers\"][\"text\"][0]\n",
        "                if isinstance(item[\"text_answers\"], dict)\n",
        "                else item[\"text_answers\"])\n",
        "        pred = item.get(answer_column_name, \"\")\n",
        "        question = item[\"original_question\"]\n",
        "\n",
        "        # Exact Match\n",
        "        if _normalize_text(gold) in _normalize_text(pred):\n",
        "            g_em += 1\n",
        "        else:\n",
        "            print(_normalize_text(pred), _normalize_text(gold))\n",
        "\n",
        "        # Year-based metrics\n",
        "        year_gold = _extract_year(gold)\n",
        "        year_pred = _extract_year(pred)\n",
        "        year_ref = _reference_year(question)\n",
        "\n",
        "        if year_gold is not None and year_pred is not None:\n",
        "            g_abs_err += abs(year_pred - year_gold)\n",
        "\n",
        "            # Trend: sign wrt reference year\n",
        "            if year_ref is not None:\n",
        "                gold_sign = np.sign(year_gold - year_ref)\n",
        "                pred_sign = np.sign(year_pred - year_ref)\n",
        "                if gold_sign == pred_sign and gold_sign != 0:\n",
        "                    g_trend_ok += 1\n",
        "            count_year += 1\n",
        "\n",
        "    exact_match = g_em / total_examples if total_examples else 0.0\n",
        "    mae = g_abs_err / count_year if count_year else 0.0\n",
        "    trend_accuracy = g_trend_ok / count_year if count_year else 0.0\n",
        "\n",
        "    print(f\"=== Evaluation for {dataset_filename} ===\")\n",
        "    print(f\"  Exact Match        : {exact_match:.4f}\")\n",
        "    print(f\"  Mean Absolute Error: {mae:.4f}\")\n",
        "    print(f\"  Trend Accuracy     : {trend_accuracy:.4f}\")\n",
        "\n",
        "    # Save metrics to JSON file\n",
        "    metrics_path = os.path.join(results_output_dir,\n",
        "                                f\"metrics_{dataset_filename.replace('.jsonl', '.json')}\")\n",
        "    metrics = {\n",
        "        \"dataset\": dataset_filename,\n",
        "        \"num_examples\": total_examples,\n",
        "        \"exact_match\": exact_match,\n",
        "        \"mae_year\": mae,\n",
        "        \"trend_accuracy\": trend_accuracy,\n",
        "    }\n",
        "\n",
        "    with open(metrics_path, 'w', encoding='utf-8') as mf:\n",
        "        json.dump(metrics, mf, indent=2)\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = evaluate_predictions(\n",
        "    results_for_this_dataset=results_for_this_dataset,\n",
        "    answer_column_name=answer_column_name,\n",
        "    dataset_filename=dataset_filename,\n",
        "    results_output_dir=results_output_dir\n",
        ")\n",
        "print(f\"\\nReturned metrics: {metrics}\")"
      ],
      "metadata": {
        "id": "4XbT-_32xZVz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}